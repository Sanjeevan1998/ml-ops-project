# docker-compose.yaml (Updated for GPU support and dynamic device preference)
version: '3.8'

services:
  legal-search-api:
    build: . 
    container_name: legal-search-api-dummy
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      # Mounts for data and models - paths inside container match ENV vars in Dockerfile
      - ./index:/app/index:ro 
      - ./metadata:/app/metadata:ro
      - ./real_pdfs:/app/pdf_data:ro
      - ./hf_cache:/root/.cache/huggingface
      - ./feedback_data:/app/feedback_data
      - /mnt/object-store-persist-group36:/app/mounted_bucket_storage:ro
      - /tmp/optimized_models:/app/optimized_models_local:ro 

    environment:
      # This variable tells main.py what to prefer.
      # For CPU-only VM or to force CPU: "cpu"
      # To attempt GPU usage on a GPU-VM: "cuda"
      # To let main.py decide based on availability: "auto"
      MODEL_DEVICE_PREFERENCE: "auto" 
      # These can override Dockerfile ENV if needed, but Dockerfile defaults are usually fine
      # MODEL_TYPE_TO_LOAD: "ONNX" # or "PYTORCH"
      # ONNX_MODEL_PATH: "/app/optimized_models_local/legal_bert_finetuned_onnx_int8_quantized"
      # EMBEDDING_MODEL: "/app/mounted_bucket_storage/model/Legal-BERT-finetuned"
      # FAISS_INDEX_PATH: "/app/mounted_bucket_storage/faissIndex/v1/real_index.faiss"
      # FAISS_MAP_PATH: "/app/mounted_bucket_storage/faissIndex/v1/real_map.pkl"
      # METADATA_PATH: "/app/mounted_bucket_storage/faissIndex/v1/real_metadata.pkl"
      # PDF_DATA_DIR: "/app/mounted_bucket_storage/LexisRaw"

    # --- GPU Configuration ---
    # This section enables GPU access for the container.
    # It will only work if the host VM has NVIDIA drivers and NVIDIA Container Toolkit installed.
    # On a CPU-only VM, Docker will likely ignore this or might warn/error if nvidia runtime isn't default.
    # It's generally safe to include; Docker just won't find GPUs to assign on a CPU VM.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1 
              capabilities: [gpu]
    networks:
      - monitoring_net

  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yaml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - monitoring_net

  grafana:
    image: grafana/grafana-oss:10.2.2
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: 'false'
    networks:
      - monitoring_net
    depends_on:
      - prometheus

networks:
  monitoring_net:
    driver: bridge

volumes:
  prometheus_data:
  grafana_data:
  hf_cache: