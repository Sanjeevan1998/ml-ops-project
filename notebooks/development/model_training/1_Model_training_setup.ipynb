{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20be33b-8aff-439f-a923-6135ff4823c2",
   "metadata": {},
   "source": [
    "## Launch and set up GPU for model training\n",
    "\n",
    "\n",
    "Run the following cell, and make sure the correct project is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8361ab-5588-492d-9aea-d48f225c172e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chi import server, context, lease\n",
    "import os, time\n",
    "\n",
    "context.version = \"1.0\" \n",
    "context.choose_project()\n",
    "context.choose_site(default=\"CHI@UC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57b810-d722-49bb-8b22-bd05c63b5151",
   "metadata": {},
   "source": [
    "Retrieve an existing lease named `node1_a100_gpu_team36` from Chameleon Cloud.\n",
    "\n",
    "Change the string in the following cell to reflect the name of *your* lease, then run it to get your lease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b60f1-46c4-46ff-8590-6c668ddb77f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = lease.get_lease(f\"node1_a100_gpu_team36\") \n",
    "l.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98a7926-82b1-49e2-90ad-184fa3265cf8",
   "metadata": {},
   "source": [
    "## Launch and set up NVIDIA A100 40GB server - with python-chi\n",
    "\n",
    "At the beginning of the lease time, we will bring up our GPU server. We will use the `python-chi` Python API to Chameleon to provision our server.\n",
    "\n",
    "> **Note**: if you don’t have access to the Chameleon Jupyter environment, or if you prefer to set up your AMD MI100 server by hand, the next section provides alternative instructions! If you want to set up your server “by hand”, skip to the next section.\n",
    "\n",
    "We will execute the cells in this notebook inside the Chameleon Jupyter environment.\n",
    "\n",
    "Run the following cell, and make sure the correct project is selected:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28b633-1c3b-4388-87e5-9f5ce24f30da",
   "metadata": {
    "tags": []
   },
   "source": [
    "The status should show as “ACTIVE” now that we are past the lease start time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b67a9b-0079-4214-8b47-53cc8d877945",
   "metadata": {},
   "source": [
    "We will use the lease to bring up a server with the `CC-Ubuntu24.04-CUDA` disk image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae439ca-eea9-4703-a62d-3b7e7ba2db5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "username = os.getenv('USER') # all exp resources will have this prefix\n",
    "s = server.Server(\n",
    "    f\"node-mltrain-{username}\", \n",
    "    reservation_id=l.node_reservations[0][\"id\"],\n",
    "    image_name=\"CC-Ubuntu24.04-CUDA\"\n",
    ")\n",
    "s.submit(idempotent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66905953-8698-483a-b0b2-21fd5ff5533a",
   "metadata": {},
   "source": [
    "Then, we’ll associate a floating IP with the instance, so that we can access it over SSH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101217f0-e706-4ba5-9421-3d49f9966010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attach a floating IP to your server\n",
    "s.associate_floating_ip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bd6c1-26fe-4bf7-9247-269f48815b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Refresh info\n",
    "s.refresh()\n",
    "s.check_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809c0f42-a94c-4b19-a1cf-5a07efd139b0",
   "metadata": {},
   "source": [
    "In the output below, make a note of the floating IP that has been assigned to your instance (in the “Addresses” row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3428f3e-e92e-4c75-a2dd-9a128e9e2fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.refresh()\n",
    "s.show(type=\"widget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8fe84-d8e0-4c26-a40b-c0150062b898",
   "metadata": {},
   "source": [
    "## Retrieve code and notebooks on the instance\n",
    "\n",
    "Now, we can use `python-chi` to execute commands on the instance, to set it up. We’ll start by retrieving the code and other materials on the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac2dbb-b725-4023-8866-ea87f03460aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"git clone --recurse-submodules https://github.com/Sanjeevan1998/ml-ops-project.git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_markdown_1_8",
   "metadata": {},
   "source": [
    "(Optional: checkout model-training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8283f9-a426-4043-8948-a9a5227fa282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"cd ml-ops-project && git checkout model-training\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18268817-7d67-4301-9590-46acaf9d2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.execute(\"cd code/model-training/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83df6e8-37f9-47ac-b88c-d3a621a99443",
   "metadata": {},
   "source": [
    "## Set up Docker\n",
    "\n",
    "To use common deep learning frameworks like Tensorflow or PyTorch, and ML training platforms like MLFlow and Ray, we can run containers that have all the prerequisite libraries necessary for these frameworks. Here, we will set up the container framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7befd-3d89-4bd6-b2f2-40d692595920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -sSL https://get.docker.com/ | sudo sh\")\n",
    "s.execute(\"sudo groupadd -f docker; sudo usermod -aG docker $USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671fa4e8-7298-4a66-a774-132ec6cf136f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up the NVIDIA container toolkit\n",
    "\n",
    "We will also install the NVIDIA container toolkit, with which we can access GPUs from inside our containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ee121-835e-4a36-9a28-7b46e01ac14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\")\n",
    "s.execute(\"sudo apt update\")\n",
    "s.execute(\"sudo apt-get install -y nvidia-container-toolkit\")\n",
    "s.execute(\"sudo nvidia-ctk runtime configure --runtime=docker\")\n",
    "s.execute(\"sudo systemctl restart docker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8100d-50f7-4246-96db-46f7e0edab47",
   "metadata": {
    "tags": []
   },
   "source": [
    "and we can install `nvtop` to monitor GPU usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8393af0-696b-4e5c-b846-522904a052c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"sudo apt update\")\n",
    "s.execute(\"sudo apt -y install nvtop\")\n",
    "\n",
    "#s.execute(\"sudo apt -y install cmake libncurses-dev libsystemd-dev libudev-dev libdrm-dev libgtest-dev\")\n",
    "#s.execute(\"git clone https://github.com/Syllo/nvtop\")\n",
    "#s.execute(\"mkdir -p nvtop/build && cd nvtop/build && cmake .. -DAMDGPU_SUPPORT=ON && sudo make install\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc641c4-3f45-44aa-ba1d-4a85533a6112",
   "metadata": {},
   "source": [
    "### Build a container image - for MLFlow section\n",
    "\n",
    "Finally, we will build a container image in which to work in the MLFlow section, that has:\n",
    "\n",
    "-   a Jupyter notebook server\n",
    "-   Pytorch and Pytorch Lightning\n",
    "-   CUDA, which allows deep learning frameworks like Pytorch to use the NVIDIA GPU accelerator\n",
    "-   and MLFlow\n",
    "\n",
    "You can see our Dockerfile for this image at: [Dockerfile.jupyter-torch-mlflow-cuda](https://github.com/teaching-on-testbeds/mltrain-chi/tree/main/docker/Dockerfile.jupyter-torch-mlflow-cuda)\n",
    "\n",
    "Building this container may take a bit of time, but that’s OK: we can get it started and then continue to the next section while it builds in the background, since we don’t need this container immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07e526-921a-4270-9726-5df09cbbb5e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.execute(\"docker build -t jupyter-legal_ai:latest -f DockerFile.jupyter-ray-complete .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e618a10-66c9-4793-93ed-29fff1dd1d5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Leave that cell running, and in the meantime, open an SSH sesson on your server. From your local terminal, run\n",
    "\n",
    "    ssh -i ~/.ssh/id_rsa_chameleon cc@A.B.C.D\n",
    "\n",
    "where\n",
    "\n",
    "-   in place of `~/.ssh/id_rsa_chameleon`, substitute the path to your own key that you had uploaded to CHI@TACC\n",
    "-   in place of `A.B.C.D`, use the floating IP address you just associated to your instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
