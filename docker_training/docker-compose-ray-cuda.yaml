version: '3.8' # Using a common modern version for Docker Compose

services:
  # MinIO object store service for Ray (e.g., for Ray Train/Tune checkpoints)
  # This is separate from your MLflow MinIO.
  ray_minio_for_cluster:
    image: minio/minio:RELEASE.2023-09-07T02-05-02Z # Using a specific stable version
    container_name: ray_minio_for_cluster
    restart: unless-stopped
    ports:
      - "9310:9000"  # Host port 9310 -> Container port 9000 (API) - CHANGED HOST PORT
      - "9311:9001"  # Host port 9311 -> Container port 9001 (Console) - CHANGED HOST PORT
    environment:
      MINIO_ROOT_USER: "ray_lab_user_distinct" # Distinct credentials
      MINIO_ROOT_PASSWORD: "ray_lab_password_distinct"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 5s
      timeout: 10s
      retries: 5
    command: server /data --console-address ":9001"
    volumes:
      - ray_lab_minio_data_vol:/data # Use a named volume

  ray_minio_create_bucket_for_cluster:
    image: minio/mc
    container_name: ray_minio_create_bucket_for_cluster
    depends_on:
      ray_minio_for_cluster:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      set -e;
      sleep 5; 
      mc config host add minio_for_ray_lab_svc http://ray_minio_for_cluster:9000 ray_lab_user_distinct ray_lab_password_distinct;
      if ! mc ls minio_for_ray_lab_svc/ray; then
        mc mb minio_for_ray_lab_svc/ray &&
        echo 'Bucket ray created in ray_minio_for_cluster';
      else
        echo 'Bucket ray already exists in ray_minio_for_cluster';
      fi"

  ray-head:
    image: legalai-ray-env:latest # YOUR COMPREHENSIVE IMAGE
    container_name: ray_head_lab_adapted
    user: root 
    entrypoint: /bin/sh 
    command: 
      - -c 
      - | 
        set -e
        echo "Ray Head: Running as $(whoami) to prepare /tmp/ray"
        mkdir -p /tmp/ray
        chown -R jovyan:users /tmp/ray 
        echo "Ray Head: Permissions set for /tmp/ray. Executing Ray start as jovyan..."
        exec /usr/local/bin/gosu jovyan ray start \
          --head \
          --port=6379 \
          --dashboard-host=0.0.0.0 \
          --block \
          --metrics-export-port=8080 
    ports:
      - "6379:6379"
      - "8265:8265"
      - "8080:8080"
    shm_size: '16gb' 
    volumes:
      - ray_lab_tmp_vol:/tmp/ray 
      - /home/cc/ml-ops-project:/home/jovyan/work 
    environment:
      - AWS_ACCESS_KEY_ID=ray_lab_user_distinct # For Ray's internal MinIO
      - AWS_SECRET_ACCESS_KEY=ray_lab_password_distinct
      - AWS_S3_ENDPOINT=http://ray_minio_for_cluster:9000 
      - RAY_GRAFANA_HOST=http://ray_grafana_lab_adapted:3000 
      - RAY_GRAFANA_IFRAME_HOST=http://${HOST_IP:-127.0.0.1}:3310 # Use HOST_IP or fallback, changed port
      - RAY_PROMETHEUS_HOST=http://ray_head_lab_adapted:8080 

  grafana: 
    image: grafana/grafana:latest
    container_name: ray_grafana_lab_adapted
    ports:
      - "3310:3000" # Host port 3310 -> Container port 3000 - CHANGED HOST PORT
    volumes:
      - ray_lab_grafana_storage_vol:/var/lib/grafana
      - ray_lab_tmp_vol:/tmp/ray:ro 
    environment:
      - GF_SECURITY_ADMIN_USER=admin 
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_SECURITY_ALLOW_EMBEDDING=true
    depends_on:
      - ray-head

  ray-worker-1:
    image: legalai-ray-env:latest # YOUR COMPREHENSIVE IMAGE
    container_name: ray_worker_1_lab_adapted
    user: root 
    entrypoint: /bin/sh
    command:
      - -c
      - |
        set -e
        echo "Ray Worker: Running as $(whoami) to prepare /tmp/ray"
        mkdir -p /tmp/ray
        chown -R jovyan:users /tmp/ray
        echo "Ray Worker: Permissions set for /tmp/ray. Executing Ray start as jovyan..."
        exec /usr/local/bin/gosu jovyan ray start --address=ray_head_lab_adapted:6379 --block
    shm_size: '16gb'
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock 
      - ray_lab_tmp_vol:/tmp/ray 
      - /home/cc/ml-ops-project:/home/jovyan/work 
    depends_on:
      - ray-head
    deploy:
      resources:
        reservations:
          devices:
            - driver: "nvidia"
              capabilities: ["gpu"]
              count: 1 
              # device_ids: ["0"] # Alternative to count:1 for specific GPU
    environment:
      - AWS_ACCESS_KEY_ID=ray_lab_user_distinct # For Ray's internal MinIO
      - AWS_SECRET_ACCESS_KEY=ray_lab_password_distinct
      - AWS_S3_ENDPOINT=http://ray_minio_for_cluster:9000
      - NVIDIA_VISIBLE_DEVICES=all 
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

volumes:
  ray_lab_grafana_storage_vol:
  ray_lab_tmp_vol:
  ray_lab_minio_data_vol:
